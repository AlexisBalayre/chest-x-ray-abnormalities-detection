{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/Users/alexis/Cranfield/AI/assignment/data/train.csv\")\n",
    "val_df = pd.read_csv(\"/Users/alexis/Cranfield/AI/assignment/data/val.csv\")\n",
    "test_df = pd.read_csv(\"/Users/alexis/Cranfield/AI/assignment/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training size:\", train_df.shape)\n",
    "print(\"Validation size :\", val_df.shape)\n",
    "print(\"Test size: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Training labels:\", np.bincount(train_df['class_id']))\n",
    "print(\"Validation labels:\", np.bincount(val_df['class_id']))\n",
    "print(\"Test labels:\", np.bincount(test_df['class_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = train_df['class_id'].unique()\n",
    "classes.sort()\n",
    "class_counts = train_df['class_id'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "plt.title('Class distribution in the training set', fontsize=15)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Class ID', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set class distribution\")\n",
    "train_df['class_id'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-rule baseline (majority class classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_counter = Counter()\n",
    "for class_id in train_df['class_id']:\n",
    "    train_counter.update([class_id])\n",
    "\n",
    "val_counter = Counter()\n",
    "for class_id in val_df['class_id']:\n",
    "    val_counter.update([class_id])\n",
    "\n",
    "test_counter = Counter()\n",
    "for class_id in test_df['class_id']:\n",
    "    test_counter.update([class_id])\n",
    "\n",
    "print(\"\\nTraining label distribution:\")\n",
    "print(sorted(train_counter.items()))\n",
    "\n",
    "print(\"\\nValidation label distribution:\")\n",
    "print(sorted(val_counter.items()))\n",
    "\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(sorted(test_counter.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = test_counter.most_common(1)[0]\n",
    "print(\"Majority class:\", majority_class[0])\n",
    "\n",
    "baseline_acc = majority_class[1] / sum(test_counter.values())\n",
    "print(\"Accuracy when always predicting the majority class:\")\n",
    "print(f\"{baseline_acc:.2f} ({baseline_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1121de970>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChestXrayDataModule import ChestXrayDataModule\n",
    "\n",
    "train_df_path = \"/Users/alexis/Cranfield/AI/assignment/data/train.csv\"\n",
    "val_df_path = \"/Users/alexis/Cranfield/AI/assignment/data/val.csv\"\n",
    "test_df_path = \"/Users/alexis/Cranfield/AI/assignment/data/test.csv\"\n",
    "hdf5_path = \"/Volumes/ALEXIS/ai_project_cranfield/dicom_images_final.hdf5\"\n",
    "\n",
    "dataModule = ChestXrayDataModule(\n",
    "    train_dataset_path=train_df_path,\n",
    "    val_dataset_path=val_df_path,\n",
    "    test_dataset_path=test_df_path,\n",
    "    hdf5_path=hdf5_path,\n",
    "    batch_size=4,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChestXrayLightningModel import ChestXrayLightningModel\n",
    "\n",
    "model = ChestXrayLightningModel(\n",
    "    learning_rate=0.005,\n",
    "    num_classes=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/alexis/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=\"auto\",\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" model.train()\n",
    "dataModule.setup(\"fit\")\n",
    "trainer.fit(model, datamodule=dataModule) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataModule.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def format_prediction_string(labels, boxes, scores):\n",
    "    pred_strings = []\n",
    "    for j in zip(labels, scores, boxes):\n",
    "        pred_strings.append(\n",
    "            \"{0} {1:.4f} {2} {3} {4} {5}\".format(\n",
    "                j[0], j[1], j[2][0], j[2][1], j[2][2], j[2][3]\n",
    "            )\n",
    "        )\n",
    "    return \" \".join(pred_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChestXrayLightningModel.load_from_checkpoint(\n",
    "    \"/Users/alexis/Cranfield/AI/assignment/Faster-R-CNN/model/version_14/checkpoints/epoch=9-step=9260.ckpt\",\n",
    "    num_classes=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=60, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_threshold = 0.4\n",
    "results = []\n",
    "model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChestXrayLightningModel(\n",
       "  (model): FasterRCNN(\n",
       "    (transform): GeneralizedRCNNTransform(\n",
       "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "        Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "    )\n",
       "    (backbone): BackboneWithFPN(\n",
       "      (body): IntermediateLayerGetter(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fpn): FeaturePyramidNetwork(\n",
       "        (inner_blocks): ModuleList(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (layer_blocks): ModuleList(\n",
       "          (0-3): 4 x Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (extra_blocks): LastLevelMaxPool()\n",
       "      )\n",
       "    )\n",
       "    (rpn): RegionProposalNetwork(\n",
       "      (anchor_generator): AnchorGenerator()\n",
       "      (head): RPNHead(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (roi_heads): RoIHeads(\n",
       "      (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "      (box_head): TwoMLPHead(\n",
       "        (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (box_predictor): FastRCNNPredictor(\n",
       "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
       "        (bbox_pred): Linear(in_features=1024, out_features=60, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (val_metric): MeanAveragePrecision()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the model is on GPU if available\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 1/1757 [00:18<8:55:26, 18.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': '27b822c5d3b354f096dfb788fd3fa636', 'PredictionString': '8 0.8928 69.38096618652344 116.62224578857422 86.6138687133789 133.91175842285156 0 0.8732 112.89633178710938 70.56173706054688 138.8718719482422 100.48268127441406 8 0.8073 175.08900451660156 145.5911102294922 181.0615997314453 151.89627075195312 8 0.7882 35.42214584350586 124.0315933227539 40.95875930786133 131.5504913330078 8 0.7735 168.79669189453125 109.6122055053711 175.3958740234375 114.38080596923828 8 0.7421 51.692481994628906 116.00086212158203 58.26260757446289 120.69606018066406 3 0.7322 83.06791687011719 137.2764434814453 163.2445831298828 168.31044006347656 8 0.6729 34.32096862792969 162.9665069580078 41.514930725097656 169.59893798828125 8 0.6681 46.89222717285156 105.73015594482422 52.8055534362793 110.87127685546875 8 0.5857 51.506587982177734 114.08540344238281 60.29948425292969 121.21923828125 8 0.5070 62.850830078125 116.72383880615234 67.71094512939453 120.38460540771484 11 0.4931 21.695070266723633 179.67578125 30.91109275817871 191.81076049804688 8 0.4564 34.81631088256836 121.9502182006836 43.86997604370117 131.5421142578125 8 0.4472 49.98402404785156 140.6312255859375 57.86082077026367 152.7525634765625 8 0.4163 55.33338928222656 133.11448669433594 64.83588409423828 141.2349395751953 8 0.4026 32.070823669433594 162.44235229492188 41.68878173828125 172.87391662597656'}\n",
      "{'image_id': 'd2ca714f8f06979acfbc0992d65fb211', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '19367e88f4634c2652d3eed0a2f1f8b2', 'PredictionString': '8 0.6877 48.97382354736328 90.81963348388672 89.87329864501953 143.19171142578125 8 0.4014 79.46736907958984 53.72148132324219 100.5177001953125 81.17709350585938'}\n",
      "{'image_id': '852ec6a0bcb9608ffee9b3fda0867f91', 'PredictionString': '3 0.8484 92.58072662353516 172.5584716796875 180.0093536376953 214.11923217773438 3 0.4909 67.61697387695312 147.0260467529297 147.7290802001953 183.01803588867188'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 2/1757 [00:21<4:40:04,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 'aa9c3097e6d2df7216be1a1642f683c9', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': 'bb541cb8a793063968903bf3fc5b68f7', 'PredictionString': '0 0.9770 122.80204772949219 39.90216064453125 142.19229125976562 63.13593292236328 3 0.9733 104.5771484375 89.35327911376953 171.29122924804688 114.15386199951172 11 0.5260 131.34640502929688 23.44124412536621 158.0930633544922 31.16642951965332 11 0.4303 80.11498260498047 23.77183723449707 102.4603500366211 34.76554489135742 11 0.4264 148.18934631347656 23.838544845581055 159.42930603027344 33.12248611450195'}\n",
      "{'image_id': '0101ad90f31ddb8fb24e9935a3dac9db', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '2a96f7ac3c6c3d856692929767006892', 'PredictionString': '14 1.0 0 0 1 1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 3/1757 [00:24<3:14:20,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': '2b33f3a742af2c0d8fce8a2a808ea409', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '9fe9aeb925c5187479ca1bf325040a65', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '522dea0833b59836405679f464299eac', 'PredictionString': '11 0.8766 73.53074645996094 13.210432052612305 102.421142578125 25.179210662841797 11 0.8398 126.71528625488281 13.625965118408203 154.3531036376953 25.250455856323242 11 0.6996 52.31689453125 147.7076873779297 63.32757568359375 159.78138732910156 10 0.6751 160.4493865966797 144.74029541015625 174.6006317138672 164.0594482421875 11 0.6402 75.3311996459961 16.489736557006836 96.96298217773438 23.56389808654785 11 0.6041 122.95785522460938 11.371065139770508 158.5264892578125 31.467777252197266 11 0.5200 164.02102661132812 149.5199737548828 173.68544006347656 163.26473999023438 10 0.4985 165.08908081054688 147.3728485107422 173.46632385253906 162.97406005859375 10 0.4962 156.6766815185547 139.38168334960938 175.53846740722656 169.7888946533203 9 0.4246 68.3100814819336 122.67942810058594 84.31839752197266 142.5010986328125 10 0.4195 53.046653747558594 145.7306671142578 63.113136291503906 159.4842071533203 11 0.4117 162.26431274414062 145.16493225097656 174.51512145996094 168.0121612548828 11 0.4056 130.1658172607422 14.511311531066895 151.7214813232422 21.681684494018555'}\n",
      "{'image_id': 'b995057fed5cd441821c8a954697ea57', 'PredictionString': '10 0.7885 16.571773529052734 120.19456481933594 97.69378662109375 174.7288055419922 10 0.7728 19.158634185791016 126.68318939208984 39.644588470458984 155.48934936523438 9 0.7372 2.936455488204956 88.75304412841797 19.920434951782227 158.1466522216797 0 0.6528 125.0164794921875 63.181339263916016 147.83973693847656 83.57939910888672 11 0.6491 48.341983795166016 42.38993835449219 69.72631072998047 62.18918991088867 11 0.5912 42.140506744384766 38.59138107299805 79.39136505126953 68.10761260986328 10 0.4495 13.62922191619873 126.42008972167969 43.02122497558594 170.3094024658203 10 0.4269 15.477211952209473 77.12638854980469 104.30681610107422 182.13043212890625 10 0.4244 21.234027862548828 134.01577758789062 37.08754348754883 151.5136260986328 7 0.4218 38.91941452026367 76.44900512695312 100.73685455322266 140.88975524902344 9 0.4088 4.014685153961182 103.16082000732422 34.613101959228516 153.74212646484375 9 0.4022 1.2004088163375854 75.78936767578125 23.442365646362305 196.1420440673828'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 4/1757 [00:28<2:35:07,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 'fc50039c45fdb6c9224bfff5ba4e64b3', 'PredictionString': '8 0.8442 40.31149673461914 96.01470947265625 61.132259368896484 111.54225158691406 8 0.7720 57.12699508666992 55.207088470458984 77.3942642211914 74.25776672363281 10 0.5129 194.8577423095703 170.20790100097656 203.6028594970703 181.32949829101562 11 0.5121 13.522947311401367 167.92788696289062 27.49553108215332 180.6807403564453 8 0.5118 64.0278091430664 77.65999603271484 71.3253402709961 84.81063842773438 10 0.4988 14.1812162399292 165.2611083984375 28.848644256591797 179.6734619140625 8 0.4857 59.10820007324219 56.68914794921875 84.6758041381836 79.67115020751953 11 0.4820 195.47828674316406 172.1232147216797 203.37908935546875 182.71197509765625 13 0.4795 135.68768310546875 47.070404052734375 193.74493408203125 111.16459655761719 11 0.4601 16.329267501831055 170.31480407714844 25.006925582885742 179.0946807861328 8 0.4600 41.10612869262695 102.48407745361328 52.25838851928711 111.0076675415039 0 0.4579 112.31464385986328 38.38639450073242 139.6358642578125 74.24092102050781 10 0.4539 15.602978706359863 167.72377014160156 25.070871353149414 178.83712768554688 6 0.4218 141.6868133544922 45.31013488769531 191.13209533691406 100.17808532714844'}\n",
      "{'image_id': '930b73d7cabc9eaf437271ad710d0a02', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '04738c36453aa559b68043a2b2d00f7f', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '9340b8c8362e2734af5bf9edecf6efac', 'PredictionString': '13 0.8285 57.51960372924805 48.669708251953125 103.2769775390625 83.09969329833984 13 0.6996 135.3506622314453 54.09408950805664 181.3875732421875 101.00104522705078 10 0.6495 196.10226440429688 184.1776123046875 208.30584716796875 202.62155151367188 11 0.6292 132.1954345703125 44.84457015991211 169.44895935058594 54.69687271118164 13 0.6202 72.81854248046875 45.420494079589844 102.23867797851562 76.79728698730469 8 0.5458 70.08399963378906 160.1428985595703 75.15833282470703 164.4535369873047 11 0.4879 197.11863708496094 188.60069274902344 207.53939819335938 201.9392547607422 11 0.4842 72.17110443115234 41.479103088378906 103.78042602539062 48.20778274536133 11 0.4797 78.55249786376953 42.31123733520508 102.13159942626953 46.53293228149414 11 0.4456 130.54086303710938 45.03680419921875 181.53810119628906 63.9149055480957 8 0.4037 56.06781005859375 67.19943237304688 60.271636962890625 71.40581512451172'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 5/1757 [00:31<2:14:50,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': '93abddc3fe8d832eac4e48ef666437cd', 'PredictionString': '3 0.9851 89.27140045166016 102.93556213378906 190.39642333984375 140.93006896972656 0 0.9513 116.31659698486328 41.300689697265625 149.6797332763672 71.92257690429688 11 0.7682 75.0792236328125 16.742355346679688 98.2991714477539 23.112510681152344 11 0.6983 70.21704864501953 16.634634017944336 102.0825424194336 25.94936752319336 11 0.6270 68.10232543945312 19.33954620361328 79.31616973876953 27.851755142211914 11 0.4083 66.09699249267578 17.207717895507812 87.56852722167969 29.15872573852539'}\n",
      "{'image_id': 'bfe751a05700d19728f9a56d2524a98a', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '59b1dc77610f1c18cf6524b476128321', 'PredictionString': '8 0.7526 127.20283508300781 64.31192016601562 160.24310302734375 103.35369873046875 13 0.7502 137.39955139160156 27.64154052734375 166.98033142089844 53.427005767822266 11 0.6577 120.18386840820312 19.790151596069336 153.67445373535156 28.115739822387695 8 0.5471 142.8754119873047 66.20231628417969 159.30125427246094 83.43933868408203 9 0.5397 87.85662841796875 44.81713104248047 113.53772735595703 78.52374267578125 8 0.4832 63.12190628051758 120.49217224121094 97.96089935302734 172.44137573242188 9 0.4698 37.585872650146484 117.57698822021484 93.82106018066406 202.8207244873047 11 0.4488 37.250083923339844 168.27615356445312 59.81651306152344 198.45193481445312 13 0.4285 147.0314178466797 33.70148468017578 166.7810516357422 51.12180709838867 6 0.4147 140.5889892578125 116.04763793945312 163.21998596191406 137.7534637451172 11 0.4112 118.44499206542969 20.471580505371094 142.3624725341797 26.460886001586914 6 0.4023 135.47996520996094 100.26744079589844 170.13197326660156 142.68055725097656'}\n",
      "{'image_id': '4500dc880a0978a7a1f91a0be2756806', 'PredictionString': '11 0.5140 119.80520629882812 18.584213256835938 148.30979919433594 26.767253875732422'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 6/1757 [00:35<2:05:09,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 'd3ef9ae515fb3cd3565e2c9875b3e0aa', 'PredictionString': '13 0.7924 56.742820739746094 37.27812194824219 94.66773223876953 66.50630950927734 11 0.7726 56.313682556152344 32.37049865722656 87.5090560913086 41.9376335144043 13 0.7265 170.00381469726562 70.1395034790039 183.5823516845703 75.80126953125 11 0.5489 24.779882431030273 136.0309600830078 36.43619155883789 147.5306854248047 13 0.5209 56.12800216674805 48.79209899902344 87.01595306396484 65.9259033203125 13 0.4844 173.38377380371094 86.91146087646484 187.66162109375 91.5996322631836 13 0.4421 166.75917053222656 69.45011138916016 185.6727752685547 79.34901428222656 0 0.4137 109.47938537597656 64.15483093261719 134.44688415527344 85.24706268310547 11 0.4062 51.89744567871094 31.204700469970703 92.78221130371094 46.75550079345703'}\n",
      "{'image_id': 'ec50aa95bd69eacf7b639c580a4f8bb0', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '328a03f1cf631960207c6f6f3026bdb1', 'PredictionString': '0 0.9856 111.08682250976562 52.253761291503906 136.14515686035156 83.78941345214844 3 0.9259 79.29718017578125 107.3747329711914 157.32107543945312 136.99676513671875 10 0.8472 44.15903854370117 94.69960021972656 102.86637878417969 148.5498046875 7 0.5546 51.74345397949219 99.21512603759766 93.78015899658203 126.39983367919922 3 0.5440 54.069435119628906 100.28801727294922 144.82545471191406 139.2211456298828 13 0.4919 143.52774047851562 57.20169448852539 163.0758514404297 77.28278350830078 11 0.4741 82.2918701171875 27.479724884033203 100.87335205078125 33.331661224365234 3 0.4680 56.05585861206055 114.57164001464844 156.170166015625 147.3712921142578 11 0.4060 117.126708984375 22.48441505432129 138.99244689941406 35.42634201049805'}\n",
      "{'image_id': 'f458843968166ba8c5af491035ce1651', 'PredictionString': '14 1.0 0 0 1 1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 7/1757 [00:38<1:55:17,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': '695b29b1efb0cc694f32a00a2d072f0b', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': 'ae2ee40dc4a0a53a87e85f1b3f9e159a', 'PredictionString': '0 0.8333 76.89088439941406 62.1424446105957 104.56791687011719 90.32196807861328 3 0.6361 38.154903411865234 129.09002685546875 148.28077697753906 172.80642700195312 11 0.4954 70.71224212646484 30.883573532104492 91.1316146850586 35.76993179321289 7 0.4405 34.00607681274414 112.05474090576172 92.6182861328125 169.67041015625 13 0.4146 42.43717575073242 103.19044494628906 75.7060775756836 117.72631072998047'}\n",
      "{'image_id': '6ee4ddeccef1ef0b04fd519822dbe176', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '69264b8eef78c43726b78a6fba59d962', 'PredictionString': '9 0.5905 86.67953491210938 65.33818054199219 104.31977081298828 97.24079895019531'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 8/1757 [00:41<1:49:32,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': '873fc048d8a429794f8d5675ed0638fb', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '6c52edbfaea1be8334fd862161a8f4e4', 'PredictionString': '0 0.9627 118.43889617919922 71.38524627685547 144.15293884277344 93.09223175048828 11 0.6498 191.75062561035156 198.95509338378906 202.28504943847656 207.53921508789062 10 0.6137 191.7054901123047 193.78167724609375 202.51280212402344 207.3608856201172 10 0.6066 12.451581001281738 191.55796813964844 24.121171951293945 204.77781677246094 13 0.5833 146.3862762451172 54.35224533081055 184.4541778564453 87.5202407836914 11 0.4553 12.478718757629395 193.99249267578125 23.5594425201416 205.56214904785156 11 0.4062 190.0781707763672 194.5523681640625 202.75936889648438 208.97206115722656'}\n",
      "{'image_id': '9146bc5c8c48b15972619c515604c408', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': 'd9b51a0471d1ea9b698c9a88c7888925', 'PredictionString': '14 1.0 0 0 1 1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 9/1757 [00:45<1:48:31,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': '6c62972a4eeaf465e0461d4d74394366', 'PredictionString': '0 0.8402 83.36894226074219 51.308921813964844 121.92523193359375 83.20845031738281 11 0.7237 62.50586700439453 22.28896713256836 94.43142700195312 31.525930404663086 11 0.6321 68.07440948486328 23.34431266784668 93.67969512939453 28.664949417114258 13 0.6099 52.8582878112793 29.312013626098633 93.95905303955078 65.12666320800781 3 0.5552 46.64847946166992 108.599853515625 135.81747436523438 135.10861206054688 11 0.5426 46.6657829284668 27.54300308227539 65.60802459716797 42.83424758911133 11 0.5015 48.372947692871094 30.18581771850586 60.85179901123047 40.78997039794922 8 0.4849 83.78641510009766 51.21919250488281 105.52715301513672 78.0285415649414 8 0.4810 50.516056060791016 101.18138885498047 94.58692169189453 131.5595703125 11 0.4407 55.7701530456543 23.06686782836914 93.64266967773438 36.8242073059082'}\n",
      "{'image_id': 'b6d76cce331d0552a4bb3e4562dad8bb', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '33cffa5ef42f15c6dbab82fd4da1b348', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '09f9a62fceffacc4d062a7fe24a626b8', 'PredictionString': '0 0.9353 114.73387908935547 67.38349151611328 145.3323516845703 98.18933868408203 9 0.9106 134.79226684570312 5.2533955574035645 174.09085083007812 33.20756149291992 9 0.8534 49.72854995727539 3.863576889038086 89.63215637207031 37.47031021118164 9 0.8092 143.9514923095703 10.210543632507324 168.0466766357422 31.712909698486328 9 0.7293 4.817552089691162 32.91011047363281 49.87076950073242 178.6414337158203 0 0.6730 92.2256851196289 66.11378479003906 144.54234313964844 106.29283142089844 8 0.6302 80.41936492919922 61.655906677246094 88.2423095703125 66.92594146728516 9 0.6142 16.080276489257812 96.10015869140625 46.595176696777344 216.29708862304688 9 0.6092 17.49039077758789 93.5601577758789 38.64283752441406 167.48663330078125 9 0.6072 41.11747360229492 1.4343889951705933 109.08224487304688 50.200565338134766 9 0.5371 20.877532958984375 108.63511657714844 34.50352478027344 162.46282958984375 9 0.5340 118.9122085571289 2.2382760047912598 184.7821807861328 39.93008804321289 8 0.5216 79.62015533447266 82.34766387939453 108.41647338867188 113.9637680053711 11 0.5053 188.8138885498047 165.78369140625 198.0409698486328 179.89593505859375 9 0.4588 75.15594482421875 1.7480474710464478 104.51390838623047 42.76691436767578 11 0.4568 38.68162536621094 136.30015563964844 51.95252227783203 154.1713104248047 10 0.4440 188.01649475097656 162.02159118652344 198.70315551757812 180.43115234375 9 0.4238 8.16269302368164 66.75696563720703 63.705596923828125 159.69020080566406 7 0.4098 79.5609130859375 82.14762878417969 106.554443359375 114.57658386230469'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 10/1757 [00:49<1:52:21,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': '924eb4734344e5808df5d15855d68178', 'PredictionString': '3 0.8390 99.61537170410156 115.13721466064453 176.63262939453125 154.53826904296875 11 0.8135 129.89785766601562 33.765625 159.8004608154297 42.3607063293457 0 0.7587 119.29157257080078 67.6592025756836 142.740478515625 93.09407043457031 13 0.7283 136.2552947998047 38.08533477783203 152.74403381347656 60.71486282348633 13 0.5899 69.77583312988281 62.492610931396484 80.35899353027344 72.8195571899414 11 0.5405 146.41334533691406 33.60192108154297 160.74952697753906 42.022579193115234 13 0.5123 69.66510009765625 37.898101806640625 101.06761169433594 73.59498596191406 11 0.5063 130.63314819335938 34.201683044433594 151.2346954345703 39.56513214111328 6 0.4959 149.1693115234375 101.7500228881836 186.1744384765625 153.94065856933594 11 0.4736 135.49087524414062 33.27254104614258 166.3207244873047 48.4268913269043 11 0.4488 76.66967010498047 34.88661193847656 104.35174560546875 44.00009536743164 13 0.4312 139.41600036621094 39.834529876708984 162.60289001464844 59.56838607788086 2 0.4214 126.94290161132812 70.99789428710938 140.9166717529297 87.8615493774414 13 0.4100 73.17350006103516 61.681270599365234 80.83409118652344 70.18618774414062'}\n",
      "{'image_id': '9caac1a690115767b3d4f97702f571d2', 'PredictionString': '0 0.8928 79.28569030761719 72.86237335205078 105.58255004882812 98.19551849365234 3 0.6466 28.547626495361328 123.98514556884766 143.7461395263672 163.39329528808594 11 0.4069 63.348472595214844 41.204505920410156 84.88484954833984 46.16297912597656 11 0.4038 57.890262603759766 40.66828155517578 87.07708740234375 48.00461196899414'}\n",
      "{'image_id': '000d68e42b71d3eac10ccc077aba07c1', 'PredictionString': '9 0.8603 27.467430114746094 0.0 89.56351470947266 26.79411506652832 0 0.8472 108.4030990600586 38.345149993896484 133.55252075195312 62.463626861572266 9 0.7797 115.4480972290039 1.2349281311035156 171.78819274902344 24.099084854125977 3 0.6224 82.13955688476562 94.8888168334961 177.59376525878906 120.89363098144531 9 0.5924 200.4971466064453 70.65607452392578 218.4944610595703 139.63633728027344 11 0.5680 43.52681350708008 21.685266494750977 85.11311340332031 33.30894470214844 9 0.5147 28.84023094177246 1.5120346546173096 178.75416564941406 24.683609008789062 9 0.4904 20.78680992126465 0.3517517149448395 69.31327819824219 35.713226318359375 9 0.4746 193.573486328125 46.94528579711914 220.0954132080078 137.4529571533203 11 0.4647 48.55001449584961 19.93999481201172 88.63571166992188 29.12986946105957 9 0.4297 88.75439453125 0.0 189.1110382080078 32.425811767578125'}\n",
      "{'image_id': '45d77bbb17ed1131a96b6fa31327a9de', 'PredictionString': '8 0.7059 54.3670654296875 107.91533660888672 98.99676513671875 158.66444396972656 8 0.6979 146.4298553466797 73.42688751220703 168.0438232421875 91.61622619628906 8 0.6207 138.653564453125 68.91840362548828 184.3881072998047 108.6355209350586 11 0.5345 30.61686134338379 175.10296630859375 43.678348541259766 190.72630310058594 8 0.5314 141.19992065429688 72.55101776123047 170.70635986328125 100.33702087402344 10 0.5296 30.981904983520508 172.7045440673828 45.071781158447266 189.64846801757812 8 0.4742 97.40901947021484 51.50779724121094 125.31938171386719 77.81844329833984 2 0.4641 101.96653747558594 56.044620513916016 124.84886169433594 75.8427734375 8 0.4532 52.688655853271484 88.90515899658203 118.7620620727539 161.19833374023438 9 0.4529 33.53110122680664 160.4162139892578 113.48402404785156 212.4566650390625 9 0.4344 135.82916259765625 123.73382568359375 200.71376037597656 160.17921447753906 0 0.4028 99.74664306640625 51.67719268798828 127.17052459716797 77.84846496582031'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 11/1757 [00:54<1:57:07,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 'aff9b5fa191d69543827088db17e6aa8', 'PredictionString': '8 0.6133 76.33366394042969 56.36619186401367 108.37760162353516 84.34020233154297 0 0.5801 80.88573455810547 55.35158920288086 119.66815948486328 86.25518798828125 11 0.5401 134.32411193847656 26.7628116607666 158.3924102783203 32.49943923950195 11 0.4683 126.85203552246094 26.126245498657227 161.6706085205078 34.7349739074707 8 0.4579 40.38801956176758 101.29743957519531 86.9546890258789 140.22438049316406'}\n",
      "{'image_id': '8f0256af9634bee76dccf87a76b03c0f', 'PredictionString': '14 1.0 0 0 1 1'}\n",
      "{'image_id': '84e9f232df2236e9dc7f7f472ff26bee', 'PredictionString': '8 0.5823 77.2928237915039 63.61411666870117 100.47843170166016 86.74855041503906 0 0.4170 77.31869506835938 62.28225326538086 104.62646484375 88.93020629882812'}\n",
      "{'image_id': '5b96a79b2f850d88b7b265f777bc8da8', 'PredictionString': '14 1.0 0 0 1 1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 11/1757 [01:34<4:09:35,  8.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_ids, images, _ \u001b[38;5;129;01min\u001b[39;00m tqdm(dataModule\u001b[38;5;241m.\u001b[39mtest_dataloader(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(outputs):\n\u001b[1;32m      8\u001b[0m             image_id \u001b[38;5;241m=\u001b[39m image_ids[i]\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/Faster-R-CNN/ChestXrayLightningModel.py:46\u001b[0m, in \u001b[0;36mChestXrayLightningModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torchvision/models/detection/generalized_rcnn.py:101\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     94\u001b[0m             degen_bb: List[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m boxes[bb_idx]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     95\u001b[0m             torch\u001b[38;5;241m.\u001b[39m_assert(\n\u001b[1;32m     96\u001b[0m                 \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     97\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll bounding boxes should have positive height and width.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Found invalid box \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdegen_bb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for target at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m             )\n\u001b[0;32m--> 101\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    103\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torchvision/models/detection/backbone_utils.py:57\u001b[0m, in \u001b[0;36mBackboneWithFPN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[0;32m---> 57\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfpn(x)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torchvision/models/_utils.py:69\u001b[0m, in \u001b[0;36mIntermediateLayerGetter.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m out \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_layers:\n\u001b[1;32m     71\u001b[0m         out_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_layers[name]\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torchvision/models/resnet.py:151\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m    150\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[0;32m--> 151\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m    154\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(out)\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cranfield/AI/assignment/chest-x-ray-abnormalities-detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "with torch.inference_mode():\n",
    "    for image_ids, images, _ in tqdm(dataModule.test_dataloader(), desc=\"Evaluating\"):\n",
    "        outputs = model(images)\n",
    "        for i, output in enumerate(outputs):\n",
    "            image_id = image_ids[i]\n",
    "            result = {\"image_id\": image_id, \"PredictionString\": \"14 1.0 0 0 1 1\"}\n",
    "\n",
    "            boxes = output[\"boxes\"].data.cpu().numpy()\n",
    "            labels = output[\"labels\"].data.cpu().numpy() - 1\n",
    "            scores = output[\"scores\"].data.cpu().numpy()\n",
    "\n",
    "            # Assuming detection_threshold is defined\n",
    "            valid = scores >= detection_threshold\n",
    "\n",
    "            if valid.any():\n",
    "                result = {\n",
    "                    \"image_id\": image_id,\n",
    "                    \"PredictionString\": format_prediction_string(\n",
    "                        labels[valid], boxes[valid], scores[valid]\n",
    "                    ),\n",
    "                }\n",
    "            \n",
    "            print(result)\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"image_id\", \"PredictionString\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" model = ChestXrayLightningModel.load_from_checkpoint(\n",
    "    \"/Users/alexis/Cranfield/AI/assignment/Faster-R-CNN/model/epoch=9-step=9260.ckpt\",\n",
    "    num_classes=15,\n",
    ")\n",
    "\n",
    "dataModule.setup(\"test\")    \n",
    "train_acc = trainer.test(dataloaders=dataModule.test_dataloader(), model=model) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def show_image_with_boxes(image, boxes, labels=None, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Visualize an image with its bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    - image: a PIL.Image or numpy array of the image.\n",
    "    - boxes: a list of bounding boxes, each defined by a list of four values [x_min, y_min, x_max, y_max].\n",
    "    - labels: (Optional) a list of labels for each bounding box.\n",
    "    - figsize: size of the figure to display.\n",
    "    \"\"\"\n",
    "    # If the image is a torch tensor, convert it to a numpy array\n",
    "    if torch.is_tensor(image):\n",
    "        image = image.numpy().transpose((1, 2, 0))\n",
    "    elif isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "\n",
    "    # Normalize the image array to 0-1 range if it's not already\n",
    "    if image.max() > 1.0:\n",
    "        image = image / 255\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "    ax.imshow(image)\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        width, height = x_max - x_min, y_max - y_min\n",
    "\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2,\n",
    "                                 edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        if labels is not None and i < len(labels):\n",
    "            label = labels[i]\n",
    "            plt.text(x_min, y_min, str(label), color='white', fontsize=12, bbox=dict(facecolor='red', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "dataModule.setup(\"fit\")\n",
    "\n",
    "for images, targets in dataModule.train_dataloader():  \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[2]\n",
    "target = targets[2]\n",
    "\n",
    "boxes = target['boxes'].numpy()  # Convert tensor to numpy if it's not already\n",
    "labels = target['labels'].numpy()  # Assuming you want to visualize labels as welltarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, visualize the image with bounding boxes\n",
    "show_image_with_boxes(image, boxes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred = pd.read_csv(\"/Users/alexis/Cranfield/AI/assignment/Faster-R-CNN/example_pred.csv\")\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_prediction_string(prediction_string):\n",
    "    \"\"\"Parse la chaîne de prédiction pour extraire les bounding boxes et les scores.\"\"\"\n",
    "    items = prediction_string.split()\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(0, len(items), 6):\n",
    "        class_id = int(items[i])\n",
    "        score = float(items[i + 1])\n",
    "        bbox = [float(coord) for coord in items[i + 2:i + 6]]\n",
    "        predictions.append({'class_id': class_id, 'score': score, 'bbox': bbox})\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_predictions_by_score(predictions, score_threshold=0.5):\n",
    "    \"\"\"Filtrer les prédictions pour ne conserver que celles avec un score supérieur au seuil.\"\"\"\n",
    "    return [pred for pred in predictions if pred['score'] > score_threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def show_image_with_predictions(image, predictions):\n",
    "    \"\"\"Afficher l'image avec les bounding boxes filtrées selon le score.\"\"\"\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.imshow(image, cmap='gray')\n",
    "\n",
    "    for pred in predictions:\n",
    "        x_min, y_min, x_max, y_max = pred['bbox']\n",
    "        width, height = x_max - x_min, y_max - y_min\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(x_min, y_min, f\"{pred['class_id']}: {pred['score']:.2f}\", color='white', fontsize=12, bbox=dict(facecolor='red', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import h5py\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def get_pixel_array_from_hdf5(hdf5_path, filename):\n",
    "    \"\"\"\n",
    "    Retrieves the pixel array for a given filename from an HDF5 file.\n",
    "\n",
    "    Parameters:\n",
    "    - hdf5_path: Path to the HDF5 file.\n",
    "    - filename: The original file name of the DICOM image.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array of the pixel data if found; None otherwise.\n",
    "    \"\"\"\n",
    "    with h5py.File(hdf5_path, \"r\") as hdf5_file:\n",
    "        # Attempt to access the dataset directly by filename.\n",
    "        # Adjust this part if a more complex naming convention is used.\n",
    "        unique_filename = None\n",
    "        for key in hdf5_file.keys():\n",
    "            if filename in key:\n",
    "                unique_filename = key\n",
    "                break\n",
    "                \n",
    "        if unique_filename is not None:\n",
    "            pixel_array = hdf5_file[unique_filename][:]\n",
    "            return pixel_array\n",
    "        else:\n",
    "            logging.error(f\"File {filename} not found in HDF5.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "with h5py.File(\"/Volumes/ALEXIS/ai_project_cranfield/dicom_images_final.hdf5\", \"r\") as hdf5_file:\n",
    "    # Count the number of datasets (keys) directly\n",
    "    num_datasets = len(hdf5_file.keys())\n",
    "\n",
    "# Print the number of datasets\n",
    "print(num_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"fad39dc356aaa2da58470c6daaba8112\"  # This should be the base name of the file you're looking for.\n",
    "pixel_array = get_pixel_array_from_hdf5(\"/Volumes/ALEXIS/ai_project_cranfield/dicom_images_final.hdf5\", filename+\".dicom\")\n",
    "plt.imshow(pixel_array, cmap=\"gray\")\n",
    "\n",
    "# print the size of the image\n",
    "original_size = pixel_array.shape[:2]  # (hauteur, largeur)\n",
    "print(original_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred[pred['image_id'] == filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsez les prédictions\n",
    "predictions = parse_prediction_string(pred['PredictionString'].values[0])\n",
    "\n",
    "# Filtrez selon un score de seuil, par exemple 0.9\n",
    "filtered_predictions = filter_predictions_by_score(predictions, 0.9)\n",
    "\n",
    "boxes = [pred['bbox'] for pred in filtered_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_bboxes(boxes, original_size, target_size):\n",
    "    \"\"\"\n",
    "    Dénormalise les bounding boxes selon la taille cible de l'image.\n",
    "\n",
    "    :param boxes: Liste des bounding boxes normalisées [x_min, y_min, x_max, y_max].\n",
    "    :param original_size: Tuple de la taille originale de l'image (height, width).\n",
    "    :param target_size: Tuple de la taille cible de l'image (height, width).\n",
    "    :return: Liste des bounding boxes dénormalisées selon la taille cible.\n",
    "    \"\"\"\n",
    "    denormalized_boxes = []\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        x_min = x_min * target_size[1] / original_size[1]\n",
    "        y_min = y_min * target_size[0] / original_size[0]\n",
    "        x_max = x_max * target_size[1] / original_size[1]\n",
    "        y_max = y_max * target_size[0] / original_size[0]\n",
    "        denormalized_boxes.append([x_min, y_min, x_max, y_max])\n",
    "    return denormalized_boxes\n",
    "\n",
    "# Dénormalisez les bounding boxes\n",
    "denormalized_boxes = denormalize_bboxes(boxes=boxes, original_size=original_size, target_size=(224, 224))\n",
    "\n",
    "# Update the filtered predictions with the denormalized boxes\n",
    "for i, pred in enumerate(filtered_predictions):\n",
    "    pred['bbox'] = denormalized_boxes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_with_predictions(pixel_array, filtered_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chest-x-ray-abnormalities-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
